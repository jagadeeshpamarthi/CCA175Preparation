Required Skills(cloudera)

Transform, Stage, and Store :

Convert a set of data values in a given format stored in HDFS into new data values or a new data format and write them into HDFS.

    Load data from HDFS for use in Spark applications

    Write the results back into HDFS using Spark

    Read and write files in a variety of file formats
    Perform standard extract, transform, load (ETL) processes on data using the Spark API

Data Analysis :

Use Spark SQL to interact with the metastore programmatically in your applications. Generate reports by using queries against loaded data.

    Use metastore tables as an input source or an output sink for Spark applications

    Understand the fundamentals of querying datasets in Spark

    Filter data using Spark

    Write queries that calculate aggregate statistics

    Join disparate datasets using Spark
    Produce ranked or sorted data

Configuration :

This is a practical exam and the candidate should be familiar with all aspects of generating a result, not just writing code.

    Supply command-line options to change your application configuration, such as increasing available memory

===========================================================================================================================


Skill Category 	                 Skill Description 	                                               Technology To Use

Data Ingest 	           Import data from a MySQL database into HDFS using Sqoop 	                     Sqoop
                           Export data to a MySQL database from HDFS using Sqoop 	                     Sqoop
                       Change the delimiter and file format of data during import using Sqoop 	       Sqoop
                       Ingest real-time and near-real-time streaming data into HDFS 	            Flume or Spark Streaming
                        Process streaming data as it is loaded onto the cluster 	                Flume or Spark Streaming
                       Load data into and out of HDFS using the Hadoop File System commands 	     HDFS Command Line
                       
Transform,Stage     	Load RDD data from HDFS for use in Spark applications 	                     Spark RDD and Spark DF
 and Store            Write the results from an RDD back into HDFS using Spark                     Spark RDD and Spark DF
                      Read and write files in a variety of file formats 	                         Spark RDD and Spark DF
                      Perform standard extract, transform, load (ETL) processes on data 	      Spark RDD, Spark DF and Hive
                      
Data Analysis 	Use metastore tables as an input source or an output sink for Spark applications 	Spark RDD, Spark DF,  
                                                                                                   Spark SQL, Hive, Impala  
                     Understand the fundamentals of querying datasets in Spark 	               Spark RDD, Spark DF,  Spark SQL
                              Filter data using Spark 	                                      Spark RDD, Spark DF,  Spark SQL
                      Write queries that calculate aggregate statistics 	                Spark DF,  Spark SQL, Hive and Impala
                       Join disparate datasets using Spark                                  	Spark RDD, Spark DF and Spark SQL
                       Produce ranked or sorted data 	                          Spark RDD, Spark DF,  Spark SQL, Hive and Impala
                       
 Configuration 	    Supply command-line options to change your application             Spark Submit and options that can be used
                  configuration, such as increasing available memory 	                          along with Spark Submit
